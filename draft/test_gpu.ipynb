{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952a3b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipython-autotime\n",
      "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython-autotime) (8.12.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython->ipython-autotime) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython->ipython-autotime) (1.16.0)\n",
      "Installing collected packages: ipython-autotime\n",
      "Successfully installed ipython-autotime-0.3.1\n",
      "time: 0 ns (started: 2023-09-05 18:14:52 +03:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad685875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda enabled: True\n",
      "cude available: True\n",
      "time: 7.75 s (started: 2023-09-05 18:15:41 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'cuda enabled: {torch.backends.cudnn.enabled}')\n",
    "print(f'cude available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52233d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-09-05 18:16:00 +03:00)\n"
     ]
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4546e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 156 ms (started: 2023-09-05 18:16:59 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import os as _os\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "\n",
    "audio_file_dir = _os.path.join(\n",
    "    'data', 'calls')\n",
    "audio_file_csv = _os.path.join(audio_file_dir, '911_first6sec', '911_metadata_6sec.csv')\n",
    "df = pd.read_csv(audio_file_csv)\n",
    "\n",
    "def get_text_from_audio(audio_file_name):\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    dirr, name = audio_file_name.split('/')\n",
    "    audio_file_path = _os.path.join(audio_file_dir, dirr, name)\n",
    "    with sr.AudioFile(audio_file_path) as src:\n",
    "        r.adjust_for_ambient_noise(src, duration=0.5)\n",
    "        audio = r.record(src)\n",
    "        return r.recognize_whisper(audio, model='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0bd3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 22s (started: 2023-09-05 18:21:51 +03:00)\n"
     ]
    }
   ],
   "source": [
    "with torch.device('cuda'):\n",
    "    df['filename'][:10].apply(get_text_from_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aede9868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min (started: 2023-09-05 18:34:29 +03:00)\n"
     ]
    }
   ],
   "source": [
    "with torch.device('cpu'):\n",
    "    df['filename'][:10].apply(get_text_from_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046a407",
   "metadata": {},
   "source": [
    "# Attempt to enable pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14256045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1eddd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d0409c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f070833dc8410083d3f30ca5a564ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2), Label(value='0 / 2'))), HBox(câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 16777216 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandarallel\\core.py\", line 158, in __call__\n    results = self.work_function(\n              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandarallel\\data_types\\series.py\", line 26, in work\n    return data.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandas\\core\\series.py\", line 4765, in apply\n    ).apply()\n      ^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandas\\core\\apply.py\", line 1201, in apply\n    return self.apply_standard()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandas\\core\\apply.py\", line 1281, in apply_standard\n    mapped = obj._map_values(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandas\\core\\base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandas\\core\\algorithms.py\", line 1812, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"lib.pyx\", line 2917, in pandas._libs.lib.map_infer\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandarallel\\progress_bars.py\", line 214, in closure\n    return user_defined_function(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1308\\509995224.py\", line 11, in get_text_from_audio\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\speech_recognition\\__init__.py\", line 1483, in recognize_whisper\n    self.whisper_model[model] = whisper.load_model(model, **load_options or {})\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\whisper\\__init__.py\", line 148, in load_model\n    model = Whisper(dims)\n            ^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\whisper\\model.py\", line 225, in __init__\n    self.encoder = AudioEncoder(\n                   ^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\whisper\\model.py\", line 153, in __init__\n    [ResidualAttentionBlock(n_state, n_head) for _ in range(n_layer)]\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\whisper\\model.py\", line 153, in <listcomp>\n    [ResidualAttentionBlock(n_state, n_head) for _ in range(n_layer)]\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\whisper\\model.py\", line 125, in __init__\n    Linear(n_state, n_mlp), nn.GELU(), Linear(n_mlp, n_state)\n                                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\USER\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 96, in __init__\n    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 16777216 bytes.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_series \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_text_from_audio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu_torch\\Lib\\site-packages\\pandarallel\\core.py:444\u001b[0m, in \u001b[0;36mparallelize_with_pipe.<locals>.closure\u001b[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mError:\n\u001b[0;32m    442\u001b[0m         progress_bars\u001b[38;5;241m.\u001b[39mset_error(worker_index)\n\u001b[1;32m--> 444\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mresults_promise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_type\u001b[38;5;241m.\u001b[39mreduce(results, reduce_extra)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu_torch\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 16777216 bytes."
     ]
    }
   ],
   "source": [
    "text_series = df['filename'][:10].parallel_apply(get_text_from_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451a782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "gpu_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
